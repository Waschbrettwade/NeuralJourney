{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd08fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "In this chapter, we will only make our Backpropagation algorithm a little more efficient using vectorization. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from numba import njit\n",
    "import matplotlib.image as img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backprop:\n",
    "\n",
    "    def sigmoid(r):\n",
    "            return (1 + np.exp(-r)) ** (-1)\n",
    "\n",
    "    def train(x_train, y_train, hidden_units = 3, learning_rate = 10e-4, tol = 10e-3):\n",
    "        # We need y_train to be 2D. There should be as many rows as there are x_train vectors\n",
    "        N = x_train.shape[0]\n",
    "        I = x_train.shape[1]\n",
    "        J = hidden_units \n",
    "        K = y_train.shape[1]\n",
    "\n",
    "        x_train = np.hstack((x_train, -np.ones(N).reshape(-1,1))).T \n",
    "        \n",
    "        W_input = np.random.rand(J, I+1)\n",
    "        W_hidden = np.random.rand(K, J+1) \n",
    "\n",
    "        m = 0\n",
    "        learning = True\n",
    "\n",
    "        while learning:\n",
    "\n",
    "            ##### ----- Phase 1: Forward Propagation ----- #####\n",
    "               \n",
    "            u_hidden = W_input @ x_train \n",
    "            h = np.vstack((Backprop.sigmoid(u_hidden), -np.ones(N)))\n",
    "            y_pred = W_hidden @ h \n",
    "            \n",
    "        \n",
    "            ##### ----- Phase 2: Backward Propagation ----- #####\n",
    "         \n",
    "            delta_output = y_pred.T - y_train \n",
    "            E_output = delta_output.T @ h.T\n",
    "            W_delta_output = -learning_rate * E_output\n",
    "            W_hidden += W_delta_output\n",
    "\n",
    "            delta_hidden = ( delta_output @ W_delta_output ) * h.T*(1 - h.T)\n",
    "            E_hidden = delta_hidden[:, :-1].T @ x_train.T\n",
    "            W_delta_hidden = -learning_rate * E_hidden\n",
    "            W_input += W_delta_hidden\n",
    "\n",
    "\n",
    "            if ( np.sum(E_hidden**2) + np.sum(E_output**2) ) < tol: \n",
    "               learning = False\n",
    "            \n",
    "            m += 1 # Iteration count\n",
    "            \n",
    "        Backprop.weights = [W_input, W_hidden]\n",
    "        Backprop.iterations = m\n",
    "\n",
    "\n",
    " ##### ----- #####\n",
    "\n",
    "\n",
    "    def predict(x):\n",
    "        N = x.shape[0]\n",
    "        x = np.hstack((x, -np.ones(N).reshape(-1,1))).T\n",
    "        output = ( Backprop.weights[1] @ np.vstack(   ( Backprop.sigmoid(Backprop.weights[0] @ x), -np.ones(N) )   ) ).T\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iterations: [2598, 4911, 6535, 8634]\nMean absolute error: [0.41321719278083047, 0.1387389734104736, 0.04151271030082801, 0.012662724617159588]\nSum of squared errors: [1.8504269564944793, 0.1983681070166248, 0.017430715116277258, 0.00174373340785554]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[1., 2., -3., 10.], [0.3, -7.8, 1., 2.]])\n",
    "y_train = np.array([[10, -3, 6, 1], [1, 1, 6, 1]])\n",
    "\n",
    "it = []\n",
    "mae = []\n",
    "sqerror = []\n",
    "\n",
    "for tol in [10e-1, 10e-2, 10e-3, 10e-4]:\n",
    "    Backprop.train(x_train, y_train, tol = tol)\n",
    "    a = Backprop.predict(x_train)\n",
    "    it.append(Backprop.iterations)\n",
    "    mae.append(np.abs((y_train - a)).mean())\n",
    "    sqerror.append( ((y_train - a)**2).sum() )\n",
    "\n",
    "print(\"Iterations:\", it)\n",
    "print(\"Mean absolute error:\", mae)\n",
    "print(\"Sum of squared errors:\", sqerror)"
   ]
  }
 ]
}